[
  {
    "objectID": "modules.html",
    "href": "modules.html",
    "title": "Modules",
    "section": "",
    "text": "Here is a list of the course modules."
  },
  {
    "objectID": "modules.html#module-1",
    "href": "modules.html#module-1",
    "title": "Modules",
    "section": "Module 1",
    "text": "Module 1\n\nSequencing Technologies"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "TRGN 515: Advanced Human Genomic Analysis Methods",
    "section": "",
    "text": "Below is the schedule of modules, slides, and assignments for the semester. Links will be updated as we progress through the course.\n\n\n\n\n\n\n\n\n\nModule\nSlides\nAssignment\nDue Date\n\n\n\n\nModule 1: Sequencing TechnologiesOverview of NGS, Nanopore, and PacBio.\n HTML PDF\n Assignment 1\nFeb 12\n\n\nModule 2: Structural Variant DetectionDefinition and types of structural variants (SV), detection of indels and SV.\n HTML PDF\n Assignment 2\nFeb 19\n\n\nModule 3: Variant Functional AnnotationVariant effect prediction, linear and logistic regression.\n HTML PDF\n Assignment 3\nMar 5\n\n\nModule 4: Genome AssemblyIntroduction to genome assembly, QC, and hybrid-assembly.\n HTML PDF\n Assignment 4\nMar 26\n\n\nModule 5: GWASIntroduction to GWAS, population structure, and linkage disequilibrium.\n HTML PDF\n Assignment 5\nApr 9\n\n\nModule 6: Epigenetics - MethylationMethylation detection with 3rd Generation sequencing.\n HTML PDF\n Assignment 6\nApr 23\n\n\nModule 7: Metagenomics IIntroduction to metagenomics, 16S amplification, and taxonomy.\n HTML PDF\n Assignment 7\nApr 30\n\n\nModule 8: Metagenomics IIWhole-genome amplification, MAGs, and functional analysis.\n HTML PDF\n Assignment 8\nApr 30"
  },
  {
    "objectID": "modules/1_sequencing_techs/1_sequencing_techs.html",
    "href": "modules/1_sequencing_techs/1_sequencing_techs.html",
    "title": "Assignment 1: Next Generation Sequencing Technologies",
    "section": "",
    "text": "DNA sequencing can be broadly defined as the determination of the identity and order of nucleic acid residues in biological samples. Bioinformatic analysis and sequencing results are greatly affected by the choice of sequencing technlogy. Sequencing technologies can be broadly categorized in three groups:\nWe will use a human genome standard (HG002) that has been extremely well-characterized as our gold standard. The HG002 genome assembly is part of an effort hosted by NIST that includes The Telomere-to-Telomere Consortium, the Human Pangenome Reference Consortium and the Genome in a Bottle Consortium, to sequence, assemble and polish the HG002 (also known as GM24385 and huAA53E0) cell line, creating a human “genome benchmark” for the HG002 reference material that covers all bases of the diploid genome and is perfectly accurate. Hence, their own “Q100” project nickname, which refers to a Phred quality score of 1 error per 10 billion bases.\nSome reference papers regarding this dataset:\nWe will compare the characteristics and SNP calls for three sequencing technologies: Illumina, PacBio HiFi, and Nanopore.",
    "crumbs": [
      "Home",
      "Module 1: Sequencing technologies",
      "Assignment 1: Next Generation Sequencing Technologies"
    ]
  },
  {
    "objectID": "modules/1_sequencing_techs/1_sequencing_techs.html#quality-check-for-short-reads---fastqc",
    "href": "modules/1_sequencing_techs/1_sequencing_techs.html#quality-check-for-short-reads---fastqc",
    "title": "Assignment 1: Next Generation Sequencing Technologies",
    "section": "Quality check for short-reads - FastQC",
    "text": "Quality check for short-reads - FastQC\nThe most widely used tool for visually evaluating fastq data is FastQC. If FastQC is ran without arguments, it will open an interactive GUI version of the software. But in most cases, we will run it in the command line.\nA basic way to call FastQC will the following command:\nfastqc # The main command call\n--extract # Extract files from output\n-o &lt;output_dir&gt; # Directory for output files\n-d &lt;temporary_dir&gt; # Directory for temporary files\n&lt;input.fq&gt; # Input fasta file\nThis code can be embedded within a python script or a cluster slurm batch job. An easy way to run it within bash in a batch script would be:\n#!/bin/bash\n\n#SBATCH --account=msalomon_1385\n#SBATCH --partition=main\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem=5G\n#SBATCH --time=1:00:00\n#SBATCH --job-name=fastqc\n#SBATCH --output=/scratch1/USER/temp/fastqc_%j.%a.out\n#SBATCH --error=/scratch1/USER/temp/fastqc_%j.%a.err\n\n# Put the input and output directories into variables for conciseness\nin_dir=/project/msalomon_1385/TRGN_515/1_exp_evolution/data/m_tuberculosis/fastq\nout_dir=/scratch1/USER/1_exp_evolution/fastq_qc\n\n# Then we loop over all files within the directory\n\nfor in_fa in $in_dir/*.fastq.gz; # Initiate loop\n    sample=$(basename $in_fa .fastq.gz) # Set up a sample variable for the output.\n    fastqc -o $out_dir/$sample --extract --dir $out_dir $in_fa\ndone # Finilize loop\nBut remember, this is just one way to run it!",
    "crumbs": [
      "Home",
      "Module 1: Sequencing technologies",
      "Assignment 1: Next Generation Sequencing Technologies"
    ]
  },
  {
    "objectID": "modules/1_sequencing_techs/1_sequencing_techs.html#quality-check-for-long-reads",
    "href": "modules/1_sequencing_techs/1_sequencing_techs.html#quality-check-for-long-reads",
    "title": "Assignment 1: Next Generation Sequencing Technologies",
    "section": "Quality check for long-reads",
    "text": "Quality check for long-reads\nYou can visualize the quality of your long reads using FastQC as you would with your short-reads. However, there’s also specific software built for long-reads. A widely used software is NanoPlot. Another option is LongQC.\n\n\n\n\n\n\nWarning\n\n\n\nIf you use FastQC on very long reads, it may run out of memory. By default, FastQC allocates a very small amount of memory (512MB), which makes it run out of memory with very long reads. The way to fix this issue is to allocate more memory using the --memory flag. So if you use FastQC, allocate 5Gb, which should be more than enough. You can do this with the command:\nfastqc --extract -o &lt;output_dir&gt; --d &lt;temporary_dir&gt; --memory 5000 &lt;input.fq&gt;\n\n\nNanoPlot is equally easy to run. It will give similar output to FastQC, but more centered on read length and base quality, which is often the obsession with Nanopore long reads.\nNanoPlot\n--fastq &lt;input.fq&gt; # Input in fastq file\n-o &lt;output_dir&gt; # Output directory\n--loglength # Set up for log read length in the plots\n\nTask 2: Run FastQC on Illumina reads\n\n\n\n\n\n\nNote\n\n\n\nRun FastqQC on the Illumina reads and answer the questions. Focus only on the following figures:\n\nPer base sequence quality\nPer sequence quality scores\nPer base sequence content\nPer sequence GC content\nPer base N content\nSequence Length Distribution\nOverrepresented sequences\nAdapter Content\n\nAnswer the following questions for each plot:\n\nWhat is the plot representing? (10pts)\nWhat quality issue (if any) is the plot showing? (10pts)\nHow would you solve the issue (if any) represented in the plot? (10pts)\n\nAnswer the questions for the forward reads only.",
    "crumbs": [
      "Home",
      "Module 1: Sequencing technologies",
      "Assignment 1: Next Generation Sequencing Technologies"
    ]
  },
  {
    "objectID": "modules/1_sequencing_techs/1_sequencing_techs.html#qc-for-short-reads---trimmomatic",
    "href": "modules/1_sequencing_techs/1_sequencing_techs.html#qc-for-short-reads---trimmomatic",
    "title": "Assignment 1: Next Generation Sequencing Technologies",
    "section": "QC for short-reads - Trimmomatic",
    "text": "QC for short-reads - Trimmomatic\nMultiple tools are commonly used to perform QC on short-reads: 1. Trimmomatic - https://github.com/usadellab/Trimmomatic 2. fastp - https://github.com/OpenGene/fastp 3. Trim Galore! - https://github.com/FelixKrueger/TrimGalore\nWe will use Trimmomatic for this. To remove adapters, you need to provide a file with the adapters for the Illumina machine the reads come from. If you installed Trimmomatic through a conda distribution, that should be within: anaconda3/share/trimmomatic/adapters/. You can also find it at their github page.\nTo run trimmomatic:\ntrimmomatic PE # Main trimmomatic function for paired-ends reads\n&lt;input_1.fastq.gz&gt; # Forward reads\n&lt;input_2.fastq.gz&gt; # Reverse reads\n&lt;output_1.fastq.gz&gt; # Output forward reads\n&lt;output_unclassified_1.fastq.gz&gt; # Output unclassified reads from forward file\n&lt;output_2.fastq.gz&gt; # Output reverse reads\n&lt;output_unclassified_2.fastq.gz&gt; # Output unclassified reads from reverse file\nSLIDINGWINDOW:&lt;window_size&gt;:&lt;quality&gt; # Sliding window for quality trimming.\nLEADING:&lt;quality&gt; # Remove leading bases under quality\nTRAILING:&lt;quality&gt; # Remove trailing bases under quality\nAVGQUAL:&lt;quality&gt; # Average quality to remove a read\nMINLEN:&lt;length&gt; # Minimum length to remove a read\nILLUMINACLIP:&lt;/path/to/adapter_file.fa&gt;:&lt;seed_mismatches&gt;:palindrome_clip_threshold&gt;:&lt;simple_clip_threshold&gt;\nFor the SLIDINGWINDOW argument, a window of window_size size moves along the read. If the average quality of the window falls below quality, the remaining of the read is clipped. This prevents reads to be removed just because of a few bad bases. This argument assumes the quality will only get worse at the end of the read.\nThe LEADING and TRAILING arguments will start at the begonning and end of the read and keep removing bases as long as their quality is below quality.\nFor ILLUMINACLIP, we need to provide the file for the adapters. This depends on the Illumina machine. The seed_mismatches argument specifies the maximum number of base mismatches allowed within a short initial sequence from the read (“seed”, 16bp) used to identify potential adapter matches, allowing for a small degree of mismatch when searching for adapters to clip. Trimmomatic uses two strategies to find adapters: the sample mode, and the palindromic mode. simple_clip_threshold is the minimum score threshold for the adapter to align to the read for clipping to take place in the simple mode. Suggested values are 7-15. palindrome_clip_threshold specifies how accurate the match between the two ‘adapter ligated’ reads must be for paired-end palindrome read alignment. Suggested values are around 30. For more information, these two strategies are extensively explained in the Trimmomatic publication.\nFor our dataset, we can run Trimmomatic within bash as follows:\nin_dir=/project/msalomon_1385/TRGN_515/1_seq_techs/illumina\nout_dir=/scratch1/USER/1_exp_evolution/fastq_pass\nadapters=/path/to/conda/share/trimmomatic/adapters/TruSeq3-PE.fa\n\n# Unlike FastQC, we need to run both forward and reverse reads together\n\nfor file in $in_dir/*_1.fastq.gz; # Initiate loop with forward reads only\n    sample=$(basename $in_fa _1.fastq.gz) # Set up a sample variable for input and output.\n    fwd=$in_dir/${sample}_1.fastq.gz # Forward read\n    rev=$in_dir/${sample}_2.fastq.gz # Reverse read\n    trimmomatic PE $fwd $rev $out_dir/${sample}_1.fastq.gz /dev/null $out_dir/${sample}_2.fastq.gz /dev/null SLIDINGWINDOW:4:5 LEADING:5 TRAILING:5 AVGQUAL:5 MINLEN:35 ILLUMINACLIP:$adapters:2:30:10\n    # Note we send unclassified reads to /dev/null\ndone # Finilize loop\n\nTask 3: Run FastQC after running Trimmomatic\n\n\n\n\n\n\nNote\n\n\n\nCompare the following FastqQC plots before and after:\n\nPer base sequence quality\nPer sequence quality scores\nPer base sequence content\nPer sequence GC content\nPer base N content\nSequence Length Distribution\nOverrepresented sequences\nAdapter Content\n\nAnswer the following questions for each plot:\n\nWhat has changed after running trimmomatic? (10pts)\nWhy did the change happen? (10pts)",
    "crumbs": [
      "Home",
      "Module 1: Sequencing technologies",
      "Assignment 1: Next Generation Sequencing Technologies"
    ]
  },
  {
    "objectID": "modules/1_sequencing_techs/1_sequencing_techs.html#short-read-mapping",
    "href": "modules/1_sequencing_techs/1_sequencing_techs.html#short-read-mapping",
    "title": "Assignment 1: Next Generation Sequencing Technologies",
    "section": "Short-read mapping",
    "text": "Short-read mapping\n\nBWA\nTo run any read mapping software, we first need a reference genome. We will use the Human Reference Genome version GRCh38. You can find the CARC location for this file at the beginning of this document.\nMost modern mappers require building an index to easily parse the reference genome during mapping. In fact, some of the biggest speed and memory improvements over early mappers was thanks to improved indexing methods. If they don’t require an index file, it’s because they index the reference genome on the fly. BWA, for instance, is based on the Burrows-wheeler Transform for powerful indexing to quickly locate where a read might align within the reference genome. The indexing for BWA can be done with the following command:\nbwa index $ref_genome\nThat will create multiple files with the same name as your reference genome, but ending in different extensions. Those are the indexes. Keep those files with the same and location as your reference genome. If a software requires those indexes, you just need to show the location of the reference genome, and it will assume the name and location of all the indexes.\nOn CARC there’s already a folder with the indexed GRCh38 reference genome, so we don’t need to do this step.\nThe basic use of BWA requires only the indexed reference genome and the files for the reads (or single file if not paired-end). To run BWA, do:\nbwa mem # Main call for the mem algorithm within BWA\n&lt;reference_genome&gt; # Reference genome\n&lt;fastq1&gt; # Forward reads\n&lt;fastq2&gt; # Reverse reads\nAn important part of the BAM file is the Read Group, especially for Illumina reads. Read groups provide technical information about flowcell, lane and multiplexing of illumina reads. This is important for finding library and sequencing issues, as well as for removing duplicates (next section!). Read Groups are added within the header with the tag RG. To find the flowcell and lane information you can use the headers of a fastq file. For modern fastq files:\nflowcell=$(zcat &lt;file.fq.gz&gt; | head -n1 | cut -d':' -f3)\nlane=$(zcat &lt;file.fq.gz&gt; | head -n1 | cut -d':' -f4)\nTwo common flags to add are the Read Group ID abd the Platform unit. You can define them as:\nrg_id=$flowcell.$lane\npu=$flowcell.$lane.$sample\nWhere $sample is your sample name. To add read groups on bwa mem, use the -R flag.\nbwa mem -R \"@RG\\tID:$rg_id\\tPU:$pu\\tPL:$pl\\tSM:$sample\" \nThe read group ID and platform information allows us to find library and sequencing bias. The sample name makes the BAM and VCF file a lot more concise later on, as the sample name is extracted from there.\nFastq files generated with older machines have different headers. You can find more information about the Fastq headers here (https://en.wikipedia.org/wiki/FASTQ_format) and about Read groups in the GATK website (https://gatk.broadinstitute.org/hc/en-us/articles/360035890671-Read-groups).\n\n\n\n\n\n\nWarning\n\n\n\nSome fastq files may have more than one flowcell and lane for all the reads if the sample was sequenced in multiple flowcell lanes. In that case, if you detect bias in the Per Tile plot in FastQC, you may have to separate the reads by flowcell and lane before mapping.\n\n\nThe output of bwa is sometimes unsorted. To ensure we have a coordinate sorted bam file (sorted by starting position), do the following:\nsamtools sort # Main call\n-@ &lt;n&gt; # Number of threads\n-T &lt;path&gt; # Temporary directory\n-O bam # Output in bam format\n-o &lt;path&gt; # Output directory\nintput_bam # Input bam file\nsamtools sort allows for other types of sorting, such as read name sorting or tag-based sorting, but coordinate sorting is by far the most common and expected by downstream bioinformatic processes.\nMany tools will require to index the output bam file for efficiency. This can be done with:\nsamtools index bam_file;\nWe can combine everything into one command using bash pipes:\nbwa mem &lt;reference_genome&gt; &lt;fastq1_path&gt; &lt;fastq2_path&gt; | samtools view -bS - | samtools sort -@ &lt;n&gt; -T &lt;path&gt; -O bam -o &lt;out_bam_path&gt;\n\nsamtools index &lt;out_bam_path&gt;",
    "crumbs": [
      "Home",
      "Module 1: Sequencing technologies",
      "Assignment 1: Next Generation Sequencing Technologies"
    ]
  },
  {
    "objectID": "modules/1_sequencing_techs/1_sequencing_techs.html#long-read-mapping",
    "href": "modules/1_sequencing_techs/1_sequencing_techs.html#long-read-mapping",
    "title": "Assignment 1: Next Generation Sequencing Technologies",
    "section": "Long-read mapping",
    "text": "Long-read mapping\nThe most widely long-read mapper is minimap2, written by the same person who developed BWA, Heng Li. As BWA, the command line command to run it is quite simple:\nminimap2\n&lt;reference_genome&gt;\n&lt;long_reads.fastq.gz&gt;\nminimap2 does not require you to provide an index, as it does it very efficienty on the fly.\nA useful feature of minimap2 is that it comes with some presets depending on the sequencing platform and the type of read. These presets take into account the typical read length and sequencing error profile for each technology.\n\nTask 5: Map reads to the reference genome\n\n\n\n\n\n\nNote\n\n\n\nUse bwa mem for short reads and minimap2 for long-reads. For minimap2, choose the appropiate platform in the presets.\nIn both cases, create a pipe with the output of the mapper and samtools for coordinate sorting.\nFor the final output, any read that maps to chromosomes other than the chromosome you are working with should be considered ambiguous. Use the right command to keep only reads that mapped to your chromosome of interest.\n\nCreate a slurm array job to run the previous code. Attach your code to the assignment (10pts)",
    "crumbs": [
      "Home",
      "Module 1: Sequencing technologies",
      "Assignment 1: Next Generation Sequencing Technologies"
    ]
  },
  {
    "objectID": "modules/1_sequencing_techs/1_sequencing_techs.html#variant-calling-in-short-reads---bcftools",
    "href": "modules/1_sequencing_techs/1_sequencing_techs.html#variant-calling-in-short-reads---bcftools",
    "title": "Assignment 1: Next Generation Sequencing Technologies",
    "section": "Variant calling in short-reads - BCFtools",
    "text": "Variant calling in short-reads - BCFtools\nFor Illumina reads, we will use BCFtools for SNP calling.\nBcftools is ran in two steps. First, we create a pileup of the alignment. A pileup is a file where aligned reads are parsed and summarized at each specific genomic position. Thus, each genomic position is scanned and reads that spanned that position are gathered (piled up!), summarizing that position with metrics such as read depth, base quality, position bias, etc. It’s basically like finding variants but without applying any specific model. Many variant calling tools use some sort of pileup, even if they don’t do it explicitly as bcftools. Typically, the output of the pileup will be pippeted to bcftools variant calling function, which applies a model to calculate the likelihood of a variant and a genotype, given the pileup at that position. Variants are often stored in a Variant Calling Format (VCF) file.\nTo run the pileup and bcftools for variant discovery:\nbcftools mpileup # Pileup function\n-f &lt;reference_genome&gt;\n-a AD,INFO/AD,ADF,INFO/ADF,ADR,INFO/ADR,DP,SP # Add tags useful for filtering\n-q &lt;n&gt; # Skip reads with read quality below n\n-Q &lt;n&gt; # Skip bases with base quality below n\n-Ou # Uncompressed output\n&lt;input_bam&gt;\n&lt;output_vcf&gt;\nOnce the pileup is done, the second step involves running the actual variant calling model. The main variant calling function can be used as:\nbcftools call # Main bcftools call function\n-m # Multiallelic calling method\n-Oz # Output in compressed format\n&lt;output.vcf.gz&gt;\nAfter calling variants, the file needs to be normalized. Variant normalization ensures genetic variants are represented in a consistent way across different data sets.\nbcftools norm\n-f &lt;reference_genome&gt;\n-Oz # Output in compressed format\n-o &lt;output.vcf.gz&gt; # Output file name\n&lt;input.vcf.gz&gt; # Input file name\nAfter calling and normalizing variants, we can soft-filter them to tag variants that we deem of low quality. Soft-filtering means that we won’t remove low-quality variants, we will just add a tag to them.\nbcftools filter # Main function\n-m+ # Append filter tags to previous tags\n# Then each tag is added depending on the condition tested, and we piped it to more filtering commands\n-s'MinMQ' # Tag to add\n-e 'INFO/MQ &lt; 20' # Condition to add tag\n&lt;input.vcf.gz&gt; | # Input file name\nbcftools filter -m+ -s'QUAL' -e 'QUAL &lt; 20' |\nbcftools filter -m+ -s'minAD' -e 'FMT/AD[:1] &lt; 10' |\n# ... as many filters as you want |\nbcftools filter -m+ -s'minADF' -e 'FMT/ADF[:1] &lt; 3' |\n-Oz # Output in compressed format\n-o &lt;output.vcf.gz&gt; # Output file name\nMany tools will require the VCF file to be indexed. This can be done as follows:\ntabix -p vcf &lt;vcf_file&gt;\n\nTask 6: Complete the Variant Calling command:**\n\n\n\n\n\n\nNote\n\n\n\nPipe the commands mpileup, call, norm and filter into one command to stream from the input bam file to the final VCF output.\nbcftools mpileup | ...\nUse the commands following this instructions. You will have to look at the help for each command:\n\nFor bcftools mpileup:\n\nUse all reads regardless of mapping quality\nKeep only bases with base quality higher or equal than 20\n\nFor bcftools call:\n\nPrint variant sites only\nDo not report indels\nKeep all alternate alleles\n\n\nApply the following filter tags in bcftools filter:\n\n‘MinMQ’ for MQ lower than 20\n‘QUAL’ for QUAL lower than 20\n‘minAD’ for allele depth lower than 20\n‘minADF’ for allele forward depth lower than 5\n‘minADR’ for allele reverse depth lower than 5\n‘MinDP’ for total depth lower than 50\n\n\n\nYour output should be a VCF with the same number of variants as before. Remember, we have not removed any variant, we have only added a filter tag in the FILTER column. Variants that pass all our filters will automatically be assigned the tag “PASS” in the FILTER column.",
    "crumbs": [
      "Home",
      "Module 1: Sequencing technologies",
      "Assignment 1: Next Generation Sequencing Technologies"
    ]
  },
  {
    "objectID": "modules/1_sequencing_techs/1_sequencing_techs.html#long-read-variant-calling",
    "href": "modules/1_sequencing_techs/1_sequencing_techs.html#long-read-variant-calling",
    "title": "Assignment 1: Next Generation Sequencing Technologies",
    "section": "Long-read variant calling",
    "text": "Long-read variant calling\nTechnically, there’s no need to use different software for long-read variant calling. However, many variant callers have been developed with long-reads in mind, and benchmarking studies show they can perform better than general variant callers. Also, long-read mapping is characterized by alignments full of small artefactual indels, which can make short-read variant callers struggle and take a long time.\n\nTask 7: Call SNPs against the human reference genome**\n\n\n\n\n\n\nNote\n\n\n\nTo be consistent between sequencing platforms, we will use a variant caller that’s platform agnostic (i.e: it’s not optimized for any especific sequencing technology or read type). We will use BCFtools.\nYou can choose any variant caller you prefer, but run the same caller for all three sequencing technologies (Illumina, PacBio HiFi, ONT). Use any filters you see necessary.\nFor this task, report your variant calling command and your choice of options and filters.\n\nCreate a slurm array job to run the SNP calling code. Call only SNPs. Attach your code to the assignment (5pts)",
    "crumbs": [
      "Home",
      "Module 1: Sequencing technologies",
      "Assignment 1: Next Generation Sequencing Technologies"
    ]
  },
  {
    "objectID": "modules/1_sequencing_techs/1_sequencing_techs.html#task-1-compare-raw-read-statistics-between-sequencing-technologies",
    "href": "modules/1_sequencing_techs/1_sequencing_techs.html#task-1-compare-raw-read-statistics-between-sequencing-technologies",
    "title": "Assignment 1: Next Generation Sequencing Technologies",
    "section": "Task 1: Compare raw read statistics between sequencing technologies",
    "text": "Task 1: Compare raw read statistics between sequencing technologies\n\n\n\n\n\n\nNoteTask 1: Compare raw read statistics between sequencing technologies\n\n\n\nFor this first task, let’s extract some basic metrics from the raw fastq files and compare between sequencing technologies. To be efficient, let’s take a random sample of 200,000 reads per sequencing technology.\nThe metrics we will report are:\n\nRead length\nAverage Base quality per read\nGC content per read\n\nOne way to do it using one of the previously shown software is:\nseqtk sample -s 100 # random seed\n&lt;fastq_file&gt; # Input fastq file\n&lt;n_reads&gt; # Number of reads to downselect\n| seqkit fx2tab # Main seqkit function to get read stats\n-q # Get average read quality\n-l # Get read length\n-g # Get GC content\n-n # Only print read name\n- &gt; &lt;output_file.txt&gt;\n\nPlot a histogram of each of the three metrics. Plot all illumina, ont and pacbio together. (10pts)\nDescribe briefly the differences in read length, base quality and GC content per sequencing platform (10pts)",
    "crumbs": [
      "Home",
      "Module 1: Sequencing technologies",
      "Assignment 1: Next Generation Sequencing Technologies"
    ]
  },
  {
    "objectID": "modules/1_sequencing_techs/1_sequencing_techs.html#sambamba",
    "href": "modules/1_sequencing_techs/1_sequencing_techs.html#sambamba",
    "title": "Assignment 1: Next Generation Sequencing Technologies",
    "section": "Sambamba",
    "text": "Sambamba\nSambamba takes a bam file as input and outputs a bam file where the read flag has been changed in some reads to reflect they are a duplicate. You can run sambamba as:\nsambamba markdup # Main call to the duplicate marking function\n--tmpdir=&lt;temp_dir&gt;\n&lt;input.bam&gt;\n&lt;output.bam&gt;\nUnfortunately, sambamba (as picard and most tools for duplicate detection) require multiple passes of the input bam file, and therefore can’t read from stdin and be used in a pipe.\nFor a efficient and fast software that can be included within pipes, you can use samtools markdup. To run samtools markup you need to do a couple of operations to ensure proper read sorting and tagging:\nsamtools collate -Ou &lt;input_bam&gt; | # Order reads by read-pairs\nsamtools fixmate -m - - -u | # Add mate coordinates and score tags\nsamtools sort - -u | # Order reads by coordinate\nsamtools markdup - &lt;output_bam&gt; # Mark duplicates\nThis code can be pipped into your previous mapping command into one nice and efficient stream!",
    "crumbs": [
      "Home",
      "Module 1: Sequencing technologies",
      "Assignment 1: Next Generation Sequencing Technologies"
    ]
  },
  {
    "objectID": "modules/1_sequencing_techs/1_sequencing_techs.html#marking-duplicates",
    "href": "modules/1_sequencing_techs/1_sequencing_techs.html#marking-duplicates",
    "title": "Assignment 1: Next Generation Sequencing Technologies",
    "section": "Marking Duplicates",
    "text": "Marking Duplicates\nThe term “duplicates” usually refers to identical sequences that appear more than once in the data. Duplicated sequences can be genuine, meaning that they are created due to real duplicated fragments in the genome. However, these duplicates can also occur due to library prep and sequencing artifacts. High rate of artificial duplicates can impact variant detection, as a variant may seem supported by many independent reads when in reality it’s just an error artificially duplicated.\nThe two most common sources for artificial duplicates in Illumina data are: * PCR duplicates - They occur when the same fragment of DNA gets amplify multiple times during library preparation, often due to overamplification * Optical duplicates - They occur during sequencing when a single amplification fluorescent cluster is incorrectly detected as multiple clusters by the optical sensor of the sequencing instrument.\n\n\n\n\n\n\nWarning\n\n\n\nDuplicate marking is not always required! Some amplicon sequencing approaches will have sequencing reads start at the same sites (the primer sites), and therefore could be marked as duplicates without representing errors. Also, in RNA-seq you would also expect high rates of sample duplication, and therefore is also not advised to remove duplicates (unless you have UMIs…)\n\n\nMost tools for marking duplicates from BAM files use the 5’ coordinates and mapping orientations of each read (or read pair), including any clipping, gaps or insertions, finding all reads that share exact genomic coordinates. It then keeps the read with the highest quality, marking the rest as duplicates. Note that often reads are not removed, but a flag is added. That’s why we call it marking duplicates!\nThe most commonly used software for marking duplicates is Picard (also implemented within GATK). However, this tool requires a lot of memory and time. I prefer another implementation of the same algorithm within the software Sambamba.\n\nSambamba\nSambamba takes a bam file as input and outputs a bam file where the read flag has been changed in some reads to reflect they are a duplicate. You can run sambamba as:\nsambamba markdup # Main call to the duplicate marking function\n--tmpdir=&lt;temp_dir&gt;\n&lt;input.bam&gt;\n&lt;output.bam&gt;\nUnfortunately, sambamba (as picard and most tools for duplicate detection) require multiple passes of the input bam file, and therefore can’t read from stdin and be used in a pipe.\nFor a efficient and fast software that can be included within pipes, you can use samtools markdup. To run samtools markup you need to do a couple of operations to ensure proper read sorting and tagging:\nsamtools collate -Ou &lt;input_bam&gt; | # Order reads by read-pairs\nsamtools fixmate -m - - -u | # Add mate coordinates and score tags\nsamtools sort - -u | # Order reads by coordinate\nsamtools markdup - &lt;output_bam&gt; # Mark duplicates\nThis code can be pipped into your previous mapping command into one nice and efficient stream!",
    "crumbs": [
      "Home",
      "Module 1: Sequencing technologies",
      "Assignment 1: Next Generation Sequencing Technologies"
    ]
  },
  {
    "objectID": "index.html#course-schedule",
    "href": "index.html#course-schedule",
    "title": "TRGN 515: Advanced Human Genomic Analysis Methods",
    "section": "",
    "text": "Below is the schedule of modules, slides, and assignments for the semester. Links will be updated as we progress through the course.\n\n\n\n\n\n\n\n\n\n\nModule\nSlides\nAssignment\nDue Date\n\n\n\n\nModule 1: Sequencing TechnologiesOverview of NGS, Nanopore, and PacBio.\n{{&lt; fa tv &gt;}} HTML{{&lt; fa file-pdf &gt;}} PDF\n{{&lt; fa pen-to-square &gt;}} Assignment 1\nFeb 12\n\n\nModule 2: AlignmentBWA, Minimap2, and SAM/BAM formats.\n{{&lt; fa tv &gt;}} HTML\n{{&lt; fa pen-to-square &gt;}} Assignment 2\nTBD\n\n\nModule 3: Variant CallingGATK, DeepVariant, and VCF files.\n{{&lt; fa tv &gt;}} HTML\n{{&lt; fa pen-to-square &gt;}} Assignment 3\nTBD"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "TRGN 515: Advanced Human Genomic Analysis Methods",
    "section": "Welcome",
    "text": "Welcome\nWelcome to TRGN 515. This course covers the fundamental algorithmic and practical aspects of bioinformatics…\n[Add any other syllabus info here, like Grading or Office Hours]"
  },
  {
    "objectID": "index.html#course-content",
    "href": "index.html#course-content",
    "title": "TRGN 515: Advanced Human Genomic Analysis Methods",
    "section": "",
    "text": "Below is the schedule of modules, slides, and assignments for the semester. Links will be updated as we progress through the course.\n\n\n\n\n\n\n\n\n\nModule\nSlides\nAssignment\nDue Date\n\n\n\n\nModule 1: Sequencing TechnologiesOverview of NGS, Nanopore, and PacBio.\n HTML PDF\n Assignment 1\nFeb 12\n\n\nModule 2: Structural Variant DetectionDefinition and types of structural variants (SV), detection of indels and SV.\n HTML PDF\n Assignment 2\nFeb 19\n\n\nModule 3: Variant Functional AnnotationVariant effect prediction, linear and logistic regression.\n HTML PDF\n Assignment 3\nMar 5\n\n\nModule 4: Genome AssemblyIntroduction to genome assembly, QC, and hybrid-assembly.\n HTML PDF\n Assignment 4\nMar 26\n\n\nModule 5: GWASIntroduction to GWAS, population structure, and linkage disequilibrium.\n HTML PDF\n Assignment 5\nApr 9\n\n\nModule 6: Epigenetics - MethylationMethylation detection with 3rd Generation sequencing.\n HTML PDF\n Assignment 6\nApr 23\n\n\nModule 7: Metagenomics IIntroduction to metagenomics, 16S amplification, and taxonomy.\n HTML PDF\n Assignment 7\nApr 30\n\n\nModule 8: Metagenomics IIWhole-genome amplification, MAGs, and functional analysis.\n HTML PDF\n Assignment 8\nApr 30"
  },
  {
    "objectID": "modules/0_intro_git/0_intro_git.html",
    "href": "modules/0_intro_git/0_intro_git.html",
    "title": "Module 0: Git and GitHub",
    "section": "",
    "text": "By the end of this module, you will be able to:\n\nConfigure your local Git environment.\nClone your class repository.\nUse the core Git commands (add, commit, push) to submit an assignment.",
    "crumbs": [
      "Home",
      "Module 0: Sequencing technologies",
      "Module 0: Git and GitHub"
    ]
  },
  {
    "objectID": "modules/0_intro_git/0_intro_git.html#learning-objectives",
    "href": "modules/0_intro_git/0_intro_git.html#learning-objectives",
    "title": "Module 0: Git and GitHub",
    "section": "",
    "text": "By the end of this module, you will be able to:\n\nConfigure your local Git environment.\nClone your class repository.\nUse the core Git commands (add, commit, push) to submit an assignment.",
    "crumbs": [
      "Home",
      "Module 0: Sequencing technologies",
      "Module 0: Git and GitHub"
    ]
  },
  {
    "objectID": "modules/0_intro_git/0_intro_git.html#github-is-a-cloud-hosting-service-for-git-repositories-that-includes-powerful-tools-for-project-management-and-collaboration.",
    "href": "modules/0_intro_git/0_intro_git.html#github-is-a-cloud-hosting-service-for-git-repositories-that-includes-powerful-tools-for-project-management-and-collaboration.",
    "title": "Module 0: Git and GitHub",
    "section": "GitHub is a cloud-hosting service for Git repositories that includes powerful tools for project management and collaboration.",
    "text": "GitHub is a cloud-hosting service for Git repositories that includes powerful tools for project management and collaboration.",
    "crumbs": [
      "Home",
      "Module 0: Sequencing technologies",
      "Module 0: Git and GitHub"
    ]
  },
  {
    "objectID": "modules/0_intro_git/0_intro_git.html#step-1-connect-git-repository-to-the-cluster.",
    "href": "modules/0_intro_git/0_intro_git.html#step-1-connect-git-repository-to-the-cluster.",
    "title": "Module 0: Git and GitHub",
    "section": "Step 1: Connect git repository to the cluster.",
    "text": "Step 1: Connect git repository to the cluster.\nYou only need do this once per assignment. It downloads the repository from GitHub to your local machine or, if the directory already exists in your local machine, it links it to the github remote repository.\n\nOption 1: Clone\nUse this option if you are starting fresh and you don’t have an existing local repository. You already have a folder in the USC server so we don’t need to do this.\n# Navigate to where you want to keep your coursework\ncd /scratch1/username\n\n# Clone your specific repository (replace URL with your classroom repo link)\ngit clone https://github.com/trgn-515-2026/USERNAME.git\n\n# Enter the directory\ncd USERNAME\n\n\nOption 2: Initiate existing folder\nSince you already have a folder for your user on the cluster, we don’t need to “clode” one from github. However, you need to turn your normal folder into a git repository.\n# 1. Enter your folder\ncd /scratch1/username\n\n# 2. Initialize Git\ngit init\ngit branch -M main\n\n# 3. Link to GitHub (Replace URL with your repo link)\ngit remote add origin https://github.com/TRGN-515-2026/USERNAME.git\n\n# 4. Pull any existing files (like the README) from GitHub\ngit pull origin main --allow-unrelated-histories",
    "crumbs": [
      "Home",
      "Module 0: Sequencing technologies",
      "Module 0: Git and GitHub"
    ]
  },
  {
    "objectID": "modules/0_intro_git/0_intro_git.html#step-2-edit-code",
    "href": "modules/0_intro_git/0_intro_git.html#step-2-edit-code",
    "title": "Module 0: Git and GitHub",
    "section": "Step 2: Edit code",
    "text": "Step 2: Edit code\nCreate files, write code, and save your work as you normally would. For this class, you will create a new folder for each assignment within your user repository.",
    "crumbs": [
      "Home",
      "Module 0: Sequencing technologies",
      "Module 0: Git and GitHub"
    ]
  },
  {
    "objectID": "modules/0_intro_git/0_intro_git.html#step-3-stage-and-commit-save",
    "href": "modules/0_intro_git/0_intro_git.html#step-3-stage-and-commit-save",
    "title": "Module 0: Git and GitHub",
    "section": "Step 3: Stage and commit (Save)",
    "text": "Step 3: Stage and commit (Save)\nGit has a two-step saving process.\n\nAdd (Stage): Select which files you want to save.\nCommit: Actually save them with a message describing what you did.\n\n# Check which files have changed\ngit status\n\n# Add everything in the current folder\ngit add .\n\n# or add a specific file\ngit add my_script.py\n\n# Save the snapshot with a message\ngit commit -m \"Completed exercise 1\"",
    "crumbs": [
      "Home",
      "Module 0: Sequencing technologies",
      "Module 0: Git and GitHub"
    ]
  },
  {
    "objectID": "modules/0_intro_git/0_intro_git.html#step-4-push-upload",
    "href": "modules/0_intro_git/0_intro_git.html#step-4-push-upload",
    "title": "Module 0: Git and GitHub",
    "section": "Step 4: Push (upload)",
    "text": "Step 4: Push (upload)\nYour commits currently live only on your computer. To submit your assignment, you must upload them to GitHub.\ngit push origin main",
    "crumbs": [
      "Home",
      "Module 0: Sequencing technologies",
      "Module 0: Git and GitHub"
    ]
  },
  {
    "objectID": "modules/0_intro_git/assignment_template.html",
    "href": "modules/0_intro_git/assignment_template.html",
    "title": "Assignment X: Topic Name",
    "section": "",
    "text": "Markdown is a lightweight markup language that allows you to format text using plain text symbols. It is the industry standard for documentation in bioinformatics and data science. It is widely used primarily due to the following characteristics:\n\nCode-Friendly: It handles code blocks and syntax highlighting natively.\nGit-Friendly: Since it is plain text, Git can track changes line-by-line (unlike Word documents).\nUniversal: It renders automatically on GitHub and converts easily to PDF or HTML."
  },
  {
    "objectID": "modules/0_intro_git/0_intro_git.html#option-1-clone",
    "href": "modules/0_intro_git/0_intro_git.html#option-1-clone",
    "title": "Module 0: Git and GitHub",
    "section": "Option 1: Clone",
    "text": "Option 1: Clone\nUse this option if you are starting fresh and you don’t have an existing local repository. You already have a folder in the USC server so we don’t need to do this.\n# Navigate to where you want to keep your coursework\ncd /scratch1/username\n\n# Clone your specific repository (replace URL with your classroom repo link)\ngit clone https://github.com/trgn-515-2026/student-repo-USERNAME.git\n\n# Enter the directory\ncd student-repo-YOURNAME",
    "crumbs": [
      "Home",
      "Module 0: Sequencing technologies",
      "Module 0: Git and GitHub"
    ]
  },
  {
    "objectID": "modules/0_intro_git/0_intro_git.html#option-2-initiate-existing-folder",
    "href": "modules/0_intro_git/0_intro_git.html#option-2-initiate-existing-folder",
    "title": "Module 0: Git and GitHub",
    "section": "Option 2: Initiate existing Folder",
    "text": "Option 2: Initiate existing Folder\nSince you already have a folder for your user on the cluster, we don’t need to “clode” one from github. However, you need to turn your normal folder into a git repository.\n# 1. Enter your folder\ncd /scratch1/username\n\n# 2. Initialize Git\ngit init\ngit branch -M main\n\n# 3. Link to GitHub (Replace URL with your repo link)\ngit remote add origin https://github.com/TRGN-515-2026/student-repo-USERNAME.git\n\n# 4. Pull any existing files (like the README) from GitHub\ngit pull origin main --allow-unrelated-histories",
    "crumbs": [
      "Home",
      "Module 0: Sequencing technologies",
      "Module 0: Git and GitHub"
    ]
  },
  {
    "objectID": "modules/0_intro_git/0_intro_git.html#step-1-pull-sync",
    "href": "modules/0_intro_git/0_intro_git.html#step-1-pull-sync",
    "title": "Module 0: Git and GitHub",
    "section": "Step 1: Pull (Sync)",
    "text": "Step 1: Pull (Sync)\nTo pull in git means to syncronize with the code from a remote repository (usually the latest version of the code).\nAlways start your work session with this. It ensures your local computer has the latest changes (e.g: you fixed a typo on the GitHub website or a collaborator merged a change).\ngit pull origin main",
    "crumbs": [
      "Home",
      "Module 0: Sequencing technologies",
      "Module 0: Git and GitHub"
    ]
  },
  {
    "objectID": "modules/0_intro_git/0_intro_git.html#step-1-join-the-trgn-515-classroom.",
    "href": "modules/0_intro_git/0_intro_git.html#step-1-join-the-trgn-515-classroom.",
    "title": "Module 0: Git and GitHub",
    "section": "Step 1: Join the TRGN-515 classroom.",
    "text": "Step 1: Join the TRGN-515 classroom.\nBefore starting, you need to accept the assignment via GitHub Classroom using the following link:\nhttps://classroom.github.com/a/nMEEuL7F\nIf you already have a github account, you can link it.\nIf you don’t have a github account, you need to create one. Clicking the link will direct you to log in or create an account. Once you create your account, verify your account using the code sent to your email.\nOnce you accept the link, authorize GitHub classroom.\nFinally, you have to select your username from the roster. Accept the assignment. Your repository will be automatically created.\nYou now have a repository on our github classroom. To change the name of this repository: 1) click on your repository; 2) Settings &gt; Repository name; 3) Change and click “Rename” twice.",
    "crumbs": [
      "Home",
      "Module 0: Sequencing technologies",
      "Module 0: Git and GitHub"
    ]
  },
  {
    "objectID": "modules/0_intro_git/0_intro_git.html#step-2-connect-git-repository-to-the-cluster.",
    "href": "modules/0_intro_git/0_intro_git.html#step-2-connect-git-repository-to-the-cluster.",
    "title": "Module 0: Git and GitHub",
    "section": "Step 2: Connect git repository to the cluster.",
    "text": "Step 2: Connect git repository to the cluster.\nYou only need do this once. It downloads the repository from GitHub to your local machine or, if the directory already exists in your local machine, it links it to the github remote repository.\n\nOption 1: Clone\nUse this option if you are starting fresh and you don’t have an existing local repository. You already have a folder in the USC server so we don’t need to do this.\n# Navigate to where you want to keep your coursework\ncd /scratch1/username\n\n# Clone your specific repository (replace URL with your classroom repo link)\ngit clone https://github.com/trgn-515-2026/USERNAME.git\n\n# Enter the directory\ncd USERNAME\n\n\nOption 2: Initiate existing folder\nSince you already have a folder for your user on the cluster, we don’t need to “clone” one from github. However, you need to turn your normal folder into a git repository.\n# 1. Enter your folder\ncd /scratch1/username\n\n# 2. Initialize Git\ngit init\ngit branch -M main\n\n# 3. Link to GitHub (Replace URL with your repo link)\ngit remote add origin https://github.com/TRGN-515-2026/USERNAME.git\n\n# 4. Pull any existing files (like the README) from GitHub\ngit pull origin main --allow-unrelated-histories",
    "crumbs": [
      "Home",
      "Module 0: Sequencing technologies",
      "Module 0: Git and GitHub"
    ]
  },
  {
    "objectID": "modules/0_intro_git/assignment_template.html#date-last-modified",
    "href": "modules/0_intro_git/assignment_template.html#date-last-modified",
    "title": "Assignment X: Topic Name",
    "section": "",
    "text": "Markdown is a lightweight markup language that allows you to format text using plain text symbols. It is the industry standard for documentation in bioinformatics and data science. It is widely used primarily due to the following characteristics:\n\nCode-Friendly: It handles code blocks and syntax highlighting natively.\nGit-Friendly: Since it is plain text, Git can track changes line-by-line (unlike Word documents).\nUniversal: It renders automatically on GitHub and converts easily to PDF or HTML."
  },
  {
    "objectID": "modules/0_intro_git/assignment_template.html#this-is-a-subheader",
    "href": "modules/0_intro_git/assignment_template.html#this-is-a-subheader",
    "title": "Assignment X: Topic Name",
    "section": "This is a subheader",
    "text": "This is a subheader\nStart each answer pasting the question as given in the pdf. After that, you can add your answer."
  },
  {
    "objectID": "modules/0_intro_git/assignment_template.html#writing-code",
    "href": "modules/0_intro_git/assignment_template.html#writing-code",
    "title": "Assignment X: Topic Name",
    "section": "Writing code",
    "text": "Writing code\nIf the answer requires code, use a code block starting and ending with single quotation marks like the one below:\n# Write your code here\nYou can add language specific code blocks by using the language’s name:\n# Write your BASH code here\nsamtools view ...\n# Write your R code here\nm1 = glm(...)\n# Write your Python code here\nimport pandas"
  },
  {
    "objectID": "modules/0_intro_git/assignment_template.html#adding-images",
    "href": "modules/0_intro_git/assignment_template.html#adding-images",
    "title": "Assignment X: Topic Name",
    "section": "Adding images",
    "text": "Adding images\nTo add an image or plot to your answer, save the image in your folder and use the following code:\n\nTo add a caption to your image:\n\n\n\nCaption text\n\n\nIf the image is not in the same folder as your markdown file, you need to put the whole path:\n\nThe square brackets are used to give the image a specific format. For instance:"
  },
  {
    "objectID": "modules/0_intro_git/assignment_template.html#other-important-syntax",
    "href": "modules/0_intro_git/assignment_template.html#other-important-syntax",
    "title": "Assignment X: Topic Name",
    "section": "Other important syntax",
    "text": "Other important syntax\nYour answer can also include lists. You can start a list with the “*” symbol for a bulleted list or with numbers for a numbered list.\n\nItem 1\nItem 2\n\nOr\n\nItem 1\nItem 2\n\nYou can also make a word italic or bold.\nOnce you finish an answer, put the next question on a different page:"
  },
  {
    "objectID": "modules/0_intro_git/assignment_template.html#adding-tables",
    "href": "modules/0_intro_git/assignment_template.html#adding-tables",
    "title": "Assignment X: Topic Name",
    "section": "Adding tables",
    "text": "Adding tables\nIf you need to include a table, you can do it like this:\n\n\n\nColumn 1\nColumn 2\n\n\n\n\nText 1\nText 2\n\n\nText 3\nText 4\n\n\n\nMaking tables can be tedius. My favority online software to turn .csv or excel tables into markdown or latex is https://www.tablesgenerator.com/markdown_tables"
  }
]